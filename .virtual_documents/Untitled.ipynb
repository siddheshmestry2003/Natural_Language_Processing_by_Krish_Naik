import pandas as pd
message=pd.read_csv("sms_spam_collection.csv")
print(message)
import re
import nltk
nltk.download('stopword')



from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
wordlemmatize=WordNetLemmatizer()


corpus=[]
for i in range(0,len(message)):
    review = re.sub("[^a-zA-Z]", " ", message['message'][i])
    review=review.lower()
    review=review.split()
    review=[wordlemmatize.lemmatize(word,) for word in review if not word in stopwords.words('english')]
    review=' '.join(review)
    corpus.append(review)

print(corpus)


from sklearn.feature_extraction.text import TfidfVectorizer
tfidf=TfidfVectorizer(max_features=100,ngram_range=(1,2))

x=tfidf.fit_transform(corpus).toarray()

x
#tfidf.vocabulary_



